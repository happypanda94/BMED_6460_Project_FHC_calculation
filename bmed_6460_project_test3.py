# -*- coding: utf-8 -*-
"""BMED_6460_project_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f3yEoGfd2g2lcj6WDRXP9J-dPzag3k_R
"""

#%%
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
import matplotlib.pyplot as plt
from skimage import io
from glob import glob
import scipy.io as sio



#%%
filepath = '/media/derik/DATA/FHC/'

train_images = sorted(glob(filepath+'training_set/*HC.png'))
train_ellipses = sorted(glob(filepath+'training_set/*HC_Annotation.png'))
train_masks = sorted(glob(filepath+'training_set/*HC_mask.png'))

train_params_df = sio.loadmat('fh_params2.mat')
train_params = train_params_df['fh_params']



#%%
from linknet import *

class UNetDataset(Dataset):

    def __init__(self, img_list, mask_list, param_list):
        self.img_list = img_list
        self.mask_list = mask_list
        self.param_list = param_list

    def __len__(self):
        return len(self.img_list)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        img_name = self.img_list[idx]
        image = io.imread(img_name, as_gray=True).astype(np.float32)
        image = np.pad(image,((2,2),(0,0)),'constant')
        image = np.expand_dims(image,0)
        mask_name = self.mask_list[idx]
        mask = io.imread(mask_name, as_gray=True).astype(np.float32)
        mask = np.pad(mask,((2,2),(0,0)),'constant')
        mask = np.expand_dims(mask,0)
        params = self.param_list[idx]
        sample = {'image': torch.from_numpy(image).to('cuda:0'), 'mask': torch.from_numpy(mask).to('cuda:0'),
                  'params': torch.from_numpy(params).to('cuda:0')}

        return sample


def dice_loss(pred, target, smooth=1e-6):
    intersection = (pred * target).sum()
    dice = (2. * intersection + smooth) / (pred.sum() + target.sum() + smooth)
    return 1 - dice

def cross_entropy2d(x, target, weight=None, size_average=True):
# Taken from https://github.com/meetshah1995/pytorch-semseg/blob/master/ptsemseg/loss.py
    n, c, h, w = x.size()
    log_p = F.log_softmax(x, dim=1)
    log_p = log_p.transpose(1, 2).transpose(2, 3).contiguous().view(-1, c)
    log_p = log_p[target.view(n * h * w, 1).repeat(1, c) >= 0]
    log_p = log_p.view(-1, c)

    mask = target >= 0
    target = target[mask]
    loss = F.nll_loss(log_p, target, ignore_index=250,
                      weight=weight, size_average=False)
    if size_average:
        loss /= mask.data.sum()
    return loss

BATCH_SIZE = 1

model = LinkNet3(n_batch=BATCH_SIZE)
print(model)

criterion1 = nn.CrossEntropyLoss()
criterion2 = nn.MSELoss()

# checking if GPU is available
if torch.cuda.is_available():
    model = model.cuda()
    criterion1 = criterion1.cuda()
    criterion2 = criterion2.cuda()
    
optimizer = optim.Adam(model.parameters(), lr=1e-3)

#%%
import torch

def filled_ellipse(params, image_size=(544,800)):
    """Create a filled ellipse with the given parameters.

    Args:
        params (torch.Tensor): A tensor containing the parameters (cx, cy, a, b, theta).
        image_size (tuple): Size of the image (height, width).

    Returns:
        torch.Tensor: A binary tensor with ones inside the ellipse and zeros outside.
    """
    ctr, a, b, theta = torch.tensor_split(params, (2, 3, 4),dim=-1)
    theta = theta*2*torch.pi

    # Compute the rotation matrix.
    radians = theta
    rotation_matrix = torch.cat([torch.cat([torch.cos(radians), -torch.sin(radians)],dim=-1),
        torch.cat([torch.sin(radians), torch.cos(radians)],dim=-1)],dim=0)
    rotation_matrix = rotation_matrix.to('cuda:0')

    # Compute the grid of pixel coordinates.
    x, y = torch.meshgrid(torch.arange(image_size[0]), torch.arange(image_size[1]))
    grid = torch.stack((x, y), dim=-1).to('cuda:0')
    grid = grid/1000.

    # Transform the grid by centering and rotating it.
    transformed_grid = grid - torch.unsqueeze(ctr,dim=0)
    transformed_grid = torch.matmul(transformed_grid, rotation_matrix)

    # Compute the equation of the ellipse and check if each point is inside it.
    ellipse_equation = (transformed_grid[:, :, 0] / (a+1e-8)) ** 2 + (transformed_grid[:, :, 1] / (b+1e-8)) ** 2
    ellipse_mask = (ellipse_equation <= 1)

    return torch.unsqueeze(torch.unsqueeze(ellipse_mask.float(),dim=0),dim=0)


#%%
# from torchviz import make_dot

# yhat = model(torch.randn(16,1,540,800).to('cuda'))

# make_dot(yhat, params=dict(list(model.named_parameters()))).render("linknet_torchviz", format="png")



#%%
train_dataset = UNetDataset(train_images[:400],train_masks[:400],train_params[:400,:])
train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True, num_workers=0)
val_dataset = UNetDataset(train_images[400:],train_masks[400:],train_params[400:,:])
val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE,shuffle=False, num_workers=0)

NO_OF_TRAINING_LOOPS = ((400)//BATCH_SIZE)+1
NO_OF_VAL_LOOPS = ((254)//BATCH_SIZE)+1

NO_OF_EPOCHS = 50


training_losses = []
val_losses = []

weights_path = filepath+'saved_weights4/'

best_val_loss = 100000.

#%%

for epoch in range(NO_OF_EPOCHS):
    if epoch> 30:
        optimizer.param_groups[0]['lr'] = 1e-4
    last_loss = 0.0
    last_dice_loss = 0.0
    running_loss = 0.0
    running_dice_loss = 0.0
    i = 0
    for i, data in enumerate(train_dataloader, 0):
        # backpropagation code here
        image, mask, params = data['image'], data['mask'], data['params']
        optimizer.zero_grad()
        # forward + backward + optimize
        pred_mask, pred_params = model(image)
        
        pred_ellipse_params = filled_ellipse(pred_params)
        
        loss = dice_loss(pred_mask,mask)+criterion1(pred_mask, mask)+0.1*criterion2(pred_params,params)
        +dice_loss(pred_ellipse_params,mask)+dice_loss(pred_ellipse_params,pred_mask)
        loss.backward()
        optimizer.step()
        

        # print statistics
        running_loss += loss.item()
        running_dice_loss += dice_loss(pred_mask,mask).item()
        
        if i % 10 == 0:
            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss/(i+1) :.8f}') # print every 10 mini-batches
            
        
        if i % NO_OF_TRAINING_LOOPS == NO_OF_TRAINING_LOOPS-1:    
            running_loss = 0.0
            running_dice_loss = 0.0
            
    last_dice_loss = running_dice_loss / (i+1)
    training_losses.append(last_dice_loss)
        

    # # evaluation
    running_loss_val = 0.0
    with torch.no_grad():
        for i, data in enumerate(val_dataloader, 0):
            val_image, val_mask, val_params = data['image'], data['mask'], data['params']
            
            val_pred_mask, val_pred_params = model(val_image)
            val_loss = dice_loss(val_pred_mask, val_mask)
            running_loss_val += val_loss
            
    avg_val_loss = running_loss_val / (i+1)
    
    val_losses.append(avg_val_loss.item())
    print(f'{epoch + 1} val_loss: {avg_val_loss :.8f}')
    
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        model_path = weights_path + 'model__{}__{}'.format(epoch, avg_val_loss)
        model_path = model_path.replace('.','_')
        torch.save(model.state_dict(), model_path)
        print('saving model to: ',model_path)


print('Finished Training')

training_losses = np.array(training_losses)
val_losses = np.array(val_losses)

#%%
plt.figure()
plt.plot(training_losses)
plt.plot(val_losses)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(('Training Dice Loss','Validation Dice Loss'))

sio.savemat('loss_history.mat',{"training_losses":training_losses,"validation_losses":val_losses})

#%%

best_model_path = '/media/derik/DATA/FHC/saved_weights4/model__42__0_021486911922693253'

model.load_state_dict(torch.load(best_model_path))



#%%
val_images_all = []
val_mask_all = []
val_params_all = []
val_mask_pred_all = []
val_params_pred_all = []

running_loss_test = 0;
with torch.no_grad():
    for i, data in enumerate(val_dataloader, 0):
      print(i)
      val_image, val_mask, val_params = data['image'], data['mask'], data['params']
      # calculate outputs by running images through the network
      val_pred_mask, val_pred_params = model(val_image)
      
      val_images_all.append(np.squeeze(val_image.detach().to('cpu').numpy()))
      val_mask_all.append(np.squeeze(val_mask.detach().to('cpu').numpy()))
      val_params_all.append(np.squeeze(val_params.detach().to('cpu').numpy()))
      val_mask_pred_all.append(np.squeeze(val_pred_mask.detach().to('cpu').numpy()))
      val_params_pred_all.append(np.squeeze(val_pred_params.detach().to('cpu').numpy()))
      
sio.savemat(weights_path+'val_results.mat',{"val_images":np.dstack(val_images_all),
                                            "val_masks": np.dstack(val_mask_all),
                                            "val_params": np.vstack(val_params_all),
                                            "val_masks_pred": np.dstack(val_mask_pred_all),
                                            "val_params_pred": np.vstack(val_params_pred_all)})



#%%
test_images = sorted(glob(filepath+'test_set/*HC.png'))

test_dataset = UNetDataset(test_images,test_images,np.zeros((len(test_images),5)))
test_dataloader = DataLoader(test_dataset, batch_size=1,shuffle=False, num_workers=0)

test_images_all = []
test_mask_all = []
test_params_all = []

running_loss_test = 0;
with torch.no_grad():
    for i, data in enumerate(test_dataloader, 0):
      print(i)
      test_image, _, _ = data['image'], data['mask'], data['params']
      # calculate outputs by running images through the network
      test_pred_mask, test_pred_params = model(test_image)
      
      test_images_all.append(np.squeeze(test_image.detach().to('cpu').numpy()))
      test_mask_all.append(np.squeeze(test_pred_mask.detach().to('cpu').numpy()))
      test_params_all.append(np.squeeze(test_pred_params.detach().to('cpu').numpy()))

      
sio.savemat(weights_path+'test_results.mat',{"test_images":np.dstack(test_images_all),
                                             "test_masks_pred": np.dstack(test_mask_all),
                                             "test_params_pred": np.vstack(test_params_all)})


#%%
data = sio.loadmat(weights_path+'val_results.mat')
val_images = data['val_images']
val_masks = data['val_masks']
val_masks_pred = data['val_masks_pred']
val_params_pred = data['val_params_pred']


#%%
n=192
img_show = np.zeros((544,800,3))
img_show[:,:,0] = val_images[:,:,n]+val_masks[:,:,n]*0.25
img_show[:,:,1] = val_images[:,:,n]
img_show[:,:,2] = val_images[:,:,n]+val_masks_pred[:,:,n]*0.5
plt.figure()
plt.imshow(img_show)

#%%
n=200
plt.figure()
plt.imshow(val_images[:,:,n]*255,cmap='gray')
plt.figure()
plt.imshow(val_masks[:,:,n]*255,cmap='gray')
plt.figure()
plt.imshow(val_masks_pred[:,:,n]*255,cmap='gray')



#%%
def dice(pred, true, k = 1):
    intersection = np.sum(pred[true==k]) * 2.0
    dice = intersection / (np.sum(pred) + np.sum(true))
    return dice

dice_scores = []

for i in range(val_images.shape[2]):
    vmp = val_masks_pred[:,:,i]>0.5
    dsc = dice(vmp,val_masks[:,:,i])
    dice_scores.append(dsc)

dice_scores = np.array(dice_scores)
print(np.mean(dice_scores),np.std(dice_scores))
#0.978510228649366 0.009098077975889287
plt.hist(dice_scores)
np.save('dsc.npy',dice_scores)


#%%
plt.boxplot(dice_scores)

#%%
val_params_gt = train_params[400:,:]
val_params_gt2 = np.zeros_like(val_params_gt)
val_params_pred2 = np.zeros_like(val_params_pred)

for i in range(val_params_gt.shape[0]):
    val_params_gt2[i,:] = val_params_gt[i,:]*np.array([1000,1000,1000,1000,1])
    val_params_pred2[i,:] = val_params_pred[i,:]*np.array([1000,1000,1000,1000,1])

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(val_params_gt2,val_params_pred2)
print(mae)

#%%
fh_pixel_sizes = train_params_df['fh_pixel_sizes']
fh_pixel_sizes = fh_pixel_sizes[0,400:]
fhc_gt = train_params_df['fhc_gt']
fhc_gt = fhc_gt[0,400:]

#%%

from skimage.feature import canny

def fit_ellipse(x, y):
    """

    Fit the coefficients a,b,c,d,e,f, representing an ellipse described by
    the formula F(x,y) = ax^2 + bxy + cy^2 + dx + ey + f = 0 to the provided
    arrays of data points x=[x1, x2, ..., xn] and y=[y1, y2, ..., yn].

    Based on the algorithm of Halir and Flusser, "Numerically stable direct
    least squares fitting of ellipses'.


    """

    D1 = np.vstack([x**2, x*y, y**2]).T
    D2 = np.vstack([x, y, np.ones(len(x))]).T
    S1 = D1.T @ D1
    S2 = D1.T @ D2
    S3 = D2.T @ D2
    T = -np.linalg.inv(S3) @ S2.T
    M = S1 + S2 @ T
    C = np.array(((0, 0, 2), (0, -1, 0), (2, 0, 0)), dtype=float)
    M = np.linalg.inv(C) @ M
    eigval, eigvec = np.linalg.eig(M)
    con = 4 * eigvec[0]* eigvec[2] - eigvec[1]**2
    ak = eigvec[:, np.nonzero(con > 0)[0]]
    return np.concatenate((ak, T @ ak)).ravel()


def cart_to_pol(coeffs):
    """

    Convert the cartesian conic coefficients, (a, b, c, d, e, f), to the
    ellipse parameters, where F(x, y) = ax^2 + bxy + cy^2 + dx + ey + f = 0.
    The returned parameters are x0, y0, ap, bp, e, phi, where (x0, y0) is the
    ellipse centre; (ap, bp) are the semi-major and semi-minor axes,
    respectively; e is the eccentricity; and phi is the rotation of the semi-
    major axis from the x-axis.

    """

    # We use the formulas from https://mathworld.wolfram.com/Ellipse.html
    # which assumes a cartesian form ax^2 + 2bxy + cy^2 + 2dx + 2fy + g = 0.
    # Therefore, rename and scale b, d and f appropriately.
    a = coeffs[0]
    b = coeffs[1] / 2
    c = coeffs[2]
    d = coeffs[3] / 2
    f = coeffs[4] / 2
    g = coeffs[5]

    den = b**2 - a*c
    if den > 0:
        raise ValueError('coeffs do not represent an ellipse: b^2 - 4ac must'
                         ' be negative!')

    # The location of the ellipse centre.
    x0, y0 = (c*d - b*f) / den, (a*f - b*d) / den

    num = 2 * (a*f**2 + c*d**2 + g*b**2 - 2*b*d*f - a*c*g)
    fac = np.sqrt((a - c)**2 + 4*b**2)
    # The semi-major and semi-minor axis lengths (these are not sorted).
    ap = np.sqrt(num / den / (fac - a - c))
    bp = np.sqrt(num / den / (-fac - a - c))

    # Sort the semi-major and semi-minor axis lengths but keep track of
    # the original relative magnitudes of width and height.
    width_gt_height = True
    if ap < bp:
        width_gt_height = False
        ap, bp = bp, ap

    # The eccentricity.
    r = (bp/ap)**2
    if r > 1:
        r = 1/r
    e = np.sqrt(1 - r)

    # The angle of anticlockwise rotation of the major-axis from x-axis.
    if b == 0:
        phi = 0 if a < c else np.pi/2
    else:
        phi = np.arctan((2.*b) / (a - c)) / 2
        if a > c:
            phi += np.pi/2
    if not width_gt_height:
        # Ensure that phi is the angle to rotate to the semi-major axis.
        phi += np.pi/2
    phi = phi % np.pi

    return x0, y0, ap, bp, e, phi

def ellipse_circumference(semi_major_axis, semi_minor_axis):
    a = semi_major_axis
    b = semi_minor_axis
    h = ((a - b) ** 2) / ((a + b) ** 2)
    circumference = np.pi * (a + b) * (1 + ((3 * h) / (10 + np.sqrt(4 - (3 * h)))))
    return circumference

fhc_pred = []

for n in range(len(fh_pixel_sizes)):
    mask = val_masks_pred[:,:,n]
    mask_edge = canny(mask,sigma=15.).astype(float)
    ellipse_idx = np.array(np.nonzero(mask_edge)).T
    ellipse_idx = ellipse_idx[np.random.choice(ellipse_idx.shape[0], ellipse_idx.shape[0]//5, replace=False), :]
    
    x = ellipse_idx[:,0]
    y = ellipse_idx[:,1]
    
    
    
    # Formulate and solve the least squares problem ||Ax - b ||^2
    coeffs = fit_ellipse(x, y)
    x0, y0, ap, bp, e, phi = cart_to_pol(coeffs)
    phi = (phi)/(2*np.pi)
    params = np.array([x0,y0,ap,bp,phi])
    
    ap_mm, bp_mm = ap*fh_pixel_sizes[n], bp*fh_pixel_sizes[n]    
    
    circumference = ellipse_circumference(ap_mm,bp_mm)
    fhc_pred.append(circumference)
    
    print(fhc_pred[n],fhc_gt[n])
    # plt.imshow(mask_edge,cmap='gray')
    
fhc_pred = np.array(fhc_pred)


#%%
from sklearn.metrics import mean_absolute_error
from sklearn.feature_selection import r_regression

mae = mean_absolute_error(fhc_gt, fhc_pred)
r_value = r_regression(np.expand_dims(fhc_pred,-1),fhc_gt)[0]
print(mae,r_value)
#2.1588870762329537 0.9072003175548533
plt.scatter(fhc_gt,fhc_pred)
plt.xlabel('Ground Truth FHC')
plt.ylabel('Predicted FHC')
plt.plot([0, 1], [0, 1], transform=plt.gca().transAxes, color='red')

#%%
plt.boxplot(fhc_pred-fhc_gt)